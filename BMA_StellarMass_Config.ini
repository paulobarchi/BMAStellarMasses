[Paths]
; old 'indir' -- I don't know why, but it seems this must be the input path
inputPath: /data/des60.b/data/palmese/lambda_star/fsps_v3.0_modified_Nov16/OUTPUTS/simha_miles_Nov2016/

[Files]
; fits input file with members 
membersInputFile: /data/des61.a/data/pbarchi/galaxyClusters/test/membersFiles/test_m1_1cluster.fits
; prefix to stellar mass output files
; example: if stellarMassOutPrefix is "sMassOut", 
; 	the stellar mass output file will be 
;	"sMassOut"+str(job)+".fits"
stellarMassOutPrefix: /data/des61.a/data/pbarchi/galaxyClusters/test/testStellarMasses_
; fits output file name for cluster stellar mass
clusterStellarMassOutFile: /data/des61.a/data/pbarchi/galaxyClusters/test/testClusterStellarMasses_full.fits
; output file to save time spent in each of the operations
; 	and total time spent as well
timeFile: /data/des61.a/data/pbarchi/galaxyClusters/test/BMA-StellarMass-Time.out

[Operations]
; specify operations desired: 
;	stellarMass and/or clusterStellarMass
stellarMass: True
clusterStellarMass: True

[Parallel]
; Comments from previous version (nike.py)
; For parallel computing, read the “Parallel Computing
; 	Instructions” section in the `runBMA-StellarMass.py`
; 	file  comments.
; This should direct you on how to adjust the batch_start 
; 	and max_of_batch parameters.
; njobs and ncores should stay the same. What I did was load up
; 	the full member output catalog from afterburner to see how
; 	many members there were, and since we can use 5 DES cluster
; 	machines (des30,40/41,50/51, though ask Marcelle you might
; 	be able to use more), I then divided the total member
;	number by 5. 
; Let’s say it was 1 million. Then each machine should
; 	compute stellar masses for 200k members. So, for your first
; 	batch of jobs on des30, let’s say, you would use 
; 	‘batch_start= 0’ and ‘max_of_batch = 200000’. 
;	Then on the next machine, des40, you would use 
;	‘batch_start = 200000’ and
; 	‘max_of_batch = 400000’. 
;	In this way you would continue until
; 	you had all 1 million members running on 500 jobs (100 for
; 	each machine) over 5 machines.
batchStart: 0
batchMax: 5355
nJobs: 100
nCores: 20
